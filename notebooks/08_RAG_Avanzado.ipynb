{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/08_RAG_Avanzado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykFbCzRy-J3R"
   },
   "source": [
    "# Tutorial: Técnicas Avanzadas de RAG para Búsqueda y Recomendación de Películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2lAl1s-AwSY"
   },
   "source": [
    "#0. Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0vUM7hbI-7je"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyv2ActUAuDS",
    "outputId": "99d09475-02ad-4e0f-95c2-c244f316c22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando recursos de NLTK...\n",
      "Recursos NLTK descargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "print(\"Descargando recursos de NLTK...\")\n",
    "import nltk\n",
    "\n",
    "# Descarga de recursos necesarios\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "print(\"Recursos NLTK descargados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgbHSN2A-tum"
   },
   "source": [
    "## 1. Búsqueda Semántica Mejorada\n",
    "- Combina sinopsis y palabras clave para mejorar la relevancia\n",
    "- Usa pesos diferentes para cada componente\n",
    "- Incluye extracción automática de keywords\n",
    "- Demuestra cómo enriquecer los resultados con información de género\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "__9FNK2d-HeG"
   },
   "outputs": [],
   "source": [
    "class SemanticSearchEnhancer:\n",
    "    \"\"\"\n",
    "    Mejora la búsqueda semántica combinando sinopsis y palabras clave.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = 'distiluse-base-multilingual-cased-v1'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.synopsis_embeddings = None\n",
    "        self.keyword_embeddings = None\n",
    "\n",
    "    def extract_keywords(self, text: str) -> str:\n",
    "        \"\"\"Extrae palabras clave del texto.\"\"\"\n",
    "        # Tokenización y eliminación de stopwords\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        keywords = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(keywords)\n",
    "\n",
    "    def prepare_data(self, df: pd.DataFrame):\n",
    "        \"\"\"Prepara los datos generando embeddings de sinopsis y keywords.\"\"\"\n",
    "        # Combinar sinopsis con géneros\n",
    "        enhanced_texts = [\n",
    "            f\"{row['descripcion']} {row['genero']}\"\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        # Extraer y embeber keywords\n",
    "        keywords = [self.extract_keywords(text) for text in enhanced_texts]\n",
    "\n",
    "        # Generar embeddings\n",
    "        print(\"Generando embeddings de sinopsis...\")\n",
    "        self.synopsis_embeddings = self.model.encode(enhanced_texts)\n",
    "        print(\"Generando embeddings de keywords...\")\n",
    "        self.keyword_embeddings = self.model.encode(keywords)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def search(self, query: str, df: pd.DataFrame, top_k: int = 3,\n",
    "              synopsis_weight: float = 0.7) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Realiza búsqueda semántica mejorada combinando similitud de\n",
    "        sinopsis y keywords.\n",
    "        \"\"\"\n",
    "        # Generar embedding de la query\n",
    "        query_embedding = self.model.encode([query])\n",
    "\n",
    "        # Calcular similitudes\n",
    "        synopsis_scores = cosine_similarity(query_embedding,\n",
    "                                         self.synopsis_embeddings)[0]\n",
    "        keyword_scores = cosine_similarity(query_embedding,\n",
    "                                        self.keyword_embeddings)[0]\n",
    "\n",
    "        # Combinar scores\n",
    "        combined_scores = (synopsis_scores * synopsis_weight +\n",
    "                         keyword_scores * (1 - synopsis_weight))\n",
    "\n",
    "        # Obtener top_k resultados\n",
    "        top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'titulo': df.iloc[idx]['titulo'],\n",
    "                'descripcion': df.iloc[idx]['descripcion'],\n",
    "                'genero': df.iloc[idx]['genero'],\n",
    "                'año': df.iloc[idx]['año'],\n",
    "                'valoracion': df.iloc[idx]['valoracion'],\n",
    "                'popularidad': df.iloc[idx]['popularidad'],\n",
    "                'score': combined_scores[idx]\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeE8SCF0-1LG"
   },
   "source": [
    "## 2. Re-Ranking Contextual\n",
    "- Reordena resultados basándose en el contexto actual\n",
    "     - Valoraciones de usuarios (rating_score)\n",
    "     - Actualidad de la película (recency_score)\n",
    "     - Popularidad general (popularity_score)\n",
    "     - Score de relevancia semántica original\n",
    "- Usa un factor alpha para balancear scores originales y contextuales\n",
    "     - Relevancia semántica (30%)\n",
    "     - Actualidad (20%)\n",
    "     - Valoraciones (30%)\n",
    "     - Popularidad (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yXI7XPoA-5_V"
   },
   "outputs": [],
   "source": [
    "class ContextualReranker:\n",
    "    \"\"\"\n",
    "    Re-ranking de resultados basado en factores contextuales como\n",
    "    valoraciones, actualidad y popularidad.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.current_year = datetime.now().year\n",
    "\n",
    "    def calculate_recency_score(self, year: int) -> float:\n",
    "        \"\"\"\n",
    "        Calcula un score basado en la actualidad de la película.\n",
    "        Películas más recientes obtienen scores más altos.\n",
    "        \"\"\"\n",
    "        age = self.current_year - year\n",
    "        return 1 / (1 + 0.1 * age)  # función de decaimiento suave\n",
    "\n",
    "    def calculate_rating_score(self, rating: float,\n",
    "                             min_rating: float = 0,\n",
    "                             max_rating: float = 10) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza la valoración al rango [0,1].\n",
    "        \"\"\"\n",
    "        return (rating - min_rating) / (max_rating - min_rating)\n",
    "\n",
    "    def calculate_popularity_score(self, popularity: float,\n",
    "                                 max_popularity: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el score de popularidad.\n",
    "        \"\"\"\n",
    "        return popularity / max_popularity\n",
    "\n",
    "    def rerank(self, results: List[Dict],\n",
    "              weights: Dict[str, float] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Re-rankea resultados basándose en múltiples factores contextuales.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        results : List[Dict]\n",
    "            Lista de resultados originales\n",
    "        weights : Dict[str, float]\n",
    "            Pesos para cada factor:\n",
    "            - 'relevance': peso para el score de relevancia original\n",
    "            - 'recency': peso para la actualidad\n",
    "            - 'rating': peso para las valoraciones\n",
    "            - 'popularity': peso para la popularidad\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'relevance': 0.3,   # score original de relevancia\n",
    "                'recency': 0.2,     # actualidad de la película\n",
    "                'rating': 0.3,      # valoraciones de usuarios\n",
    "                'popularity': 0.2    # popularidad general\n",
    "            }\n",
    "\n",
    "        # Encontrar máximo de popularidad para normalización\n",
    "        max_popularity = max(r['popularidad'] for r in results)\n",
    "\n",
    "        # Calcular scores contextuales\n",
    "        for result in results:\n",
    "            # Score de actualidad\n",
    "            recency_score = self.calculate_recency_score(result['año'])\n",
    "\n",
    "            # Score de valoración\n",
    "            rating_score = self.calculate_rating_score(result['valoracion'])\n",
    "\n",
    "            # Score de popularidad\n",
    "            popularity_score = self.calculate_popularity_score(\n",
    "                result['popularidad'],\n",
    "                max_popularity\n",
    "            )\n",
    "\n",
    "            # Combinar todos los scores\n",
    "            result['final_score'] = (\n",
    "                weights['relevance'] * result['score'] +\n",
    "                weights['recency'] * recency_score +\n",
    "                weights['rating'] * rating_score +\n",
    "                weights['popularity'] * popularity_score\n",
    "            )\n",
    "\n",
    "            # Guardar scores individuales para análisis\n",
    "            result['score_components'] = {\n",
    "                'relevance': result['score'],\n",
    "                'recency': recency_score,\n",
    "                'rating': rating_score,\n",
    "                'popularity': popularity_score\n",
    "            }\n",
    "\n",
    "        # Reordenar resultados\n",
    "        return sorted(results, key=lambda x: x['final_score'], reverse=True)\n",
    "\n",
    "    def explain_ranking(self, result: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Genera una explicación del ranking para un resultado.\n",
    "        \"\"\"\n",
    "        components = result['score_components']\n",
    "        explanation = f\"Ranking para '{result['titulo']}':\\n\"\n",
    "        explanation += f\"- Relevancia semántica: {components['relevance']:.3f}\\n\"\n",
    "        explanation += f\"- Factor de actualidad: {components['recency']:.3f}\\n\"\n",
    "        explanation += f\"- Valoración usuarios: {components['rating']:.3f}\\n\"\n",
    "        explanation += f\"- Índice popularidad: {components['popularity']:.3f}\\n\"\n",
    "        explanation += f\"Score final: {result['final_score']:.3f}\"\n",
    "        return explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2o_2Oe2_D36"
   },
   "source": [
    "## 3. Personalización Avanzada\n",
    "\n",
    "- Mantiene perfiles de usuario con preferencias\n",
    "- Actualiza perfiles basándose en interacciones\n",
    "- Ajusta pesos de búsqueda según el perfil\n",
    "- Considera géneros favoritos y búsquedas recientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sJW9BYet_JE4"
   },
   "outputs": [],
   "source": [
    "class PersonalizationEngine:\n",
    "    \"\"\"\n",
    "    Motor de personalización que mantiene y utiliza perfiles de usuario\n",
    "    para personalizar los resultados de búsqueda.\n",
    "\n",
    "    El motor mantiene un registro de:\n",
    "    - Preferencias de género\n",
    "    - Películas que le han gustado al usuario\n",
    "    - Historial de búsquedas recientes\n",
    "\n",
    "    Y proporciona pesos personalizados para el re-ranking basados en este perfil.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa el motor de personalización con un diccionario vacío de perfiles.\n",
    "        \"\"\"\n",
    "        self.user_profiles = {}\n",
    "\n",
    "    def _initialize_profile(self, user_id: str) -> None:\n",
    "        \"\"\"\n",
    "        Inicializa un nuevo perfil de usuario con estructura predefinida.\n",
    "\n",
    "        Args:\n",
    "            user_id (str): Identificador único del usuario\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            self.user_profiles[user_id] = {\n",
    "                'genre_preferences': {},     # Contador de géneros preferidos\n",
    "                'recent_searches': [],       # Lista de búsquedas recientes\n",
    "                'liked_movies': set(),       # Conjunto de películas favoritas\n",
    "                'interaction_count': 0       # Contador total de interacciones\n",
    "            }\n",
    "\n",
    "    def update_profile(self, user_id: str, interaction: Dict[str, any]) -> None:\n",
    "        \"\"\"\n",
    "        Actualiza el perfil del usuario basado en una nueva interacción.\n",
    "\n",
    "        Args:\n",
    "            user_id (str): Identificador único del usuario\n",
    "            interaction (Dict): Diccionario con la información de la interacción\n",
    "                Puede contener:\n",
    "                - 'genero': género(s) de la película\n",
    "                - 'liked_movie': título de una película que le gustó\n",
    "                - 'query': texto de búsqueda realizada\n",
    "        \"\"\"\n",
    "        # Asegurar que existe el perfil\n",
    "        self._initialize_profile(user_id)\n",
    "        profile = self.user_profiles[user_id]\n",
    "\n",
    "        # Actualizar preferencias de género\n",
    "        if 'genero' in interaction:\n",
    "            genres = interaction['genero'].split(', ')\n",
    "            for genre in genres:\n",
    "                profile['genre_preferences'][genre] = \\\n",
    "                    profile['genre_preferences'].get(genre, 0) + 1\n",
    "\n",
    "        # Actualizar películas que le gustaron\n",
    "        if 'liked_movie' in interaction:\n",
    "            profile['liked_movies'].add(interaction['liked_movie'])\n",
    "\n",
    "        # Actualizar búsquedas recientes\n",
    "        if 'query' in interaction:\n",
    "            profile['recent_searches'].append(interaction['query'])\n",
    "            # Mantener solo las últimas 5 búsquedas\n",
    "            profile['recent_searches'] = profile['recent_searches'][-5:]\n",
    "\n",
    "        # Incrementar contador de interacciones\n",
    "        profile['interaction_count'] += 1\n",
    "\n",
    "    def get_user_preferences(self, user_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Obtiene un resumen de las preferencias del usuario.\n",
    "\n",
    "        Args:\n",
    "            user_id (str): Identificador único del usuario\n",
    "\n",
    "        Returns:\n",
    "            Dict: Resumen de preferencias incluyendo géneros favoritos,\n",
    "                  películas que le gustaron y búsquedas recientes\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            return None\n",
    "\n",
    "        profile = self.user_profiles[user_id]\n",
    "        return {\n",
    "            'favorite_genres': dict(sorted(\n",
    "                profile['genre_preferences'].items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )),\n",
    "            'liked_movies': list(profile['liked_movies']),\n",
    "            'recent_searches': profile['recent_searches']\n",
    "        }\n",
    "\n",
    "    def get_personalized_weights(self, user_id: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calcula y devuelve pesos personalizados para el re-ranking basados\n",
    "        en el perfil del usuario.\n",
    "\n",
    "        Los pesos se ajustan según:\n",
    "        - La diversidad de géneros que le gustan al usuario\n",
    "        - La cantidad de interacciones realizadas\n",
    "        - Sus preferencias específicas\n",
    "\n",
    "        Args:\n",
    "            user_id (str): Identificador único del usuario\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: Diccionario con los pesos para cada factor:\n",
    "                - 'relevance': peso para relevancia semántica y género\n",
    "                - 'recency': peso para la actualidad de la película\n",
    "                - 'rating': peso para las valoraciones de usuarios\n",
    "                - 'popularity': peso para la popularidad general\n",
    "        \"\"\"\n",
    "        # Si no existe el usuario, devolver pesos por defecto\n",
    "        if user_id not in self.user_profiles:\n",
    "            return {\n",
    "                'relevance': 0.3,  # combina relevancia semántica y género\n",
    "                'recency': 0.2,    # actualidad de la película\n",
    "                'rating': 0.3,     # valoraciones de usuarios\n",
    "                'popularity': 0.2   # popularidad general\n",
    "            }\n",
    "\n",
    "        profile = self.user_profiles[user_id]\n",
    "\n",
    "        # Analizar diversidad de géneros\n",
    "        genre_diversity = len(profile['genre_preferences'])\n",
    "\n",
    "        # Analizar nivel de interacción\n",
    "        interaction_level = min(profile['interaction_count'] / 10.0, 1.0)\n",
    "\n",
    "        if genre_diversity < 3:\n",
    "            # Usuario con preferencias específicas\n",
    "            return {\n",
    "                'relevance': 0.4,  # más peso a relevancia y género\n",
    "                'recency': 0.2,    # peso moderado a actualidad\n",
    "                'rating': 0.3,     # peso significativo a valoraciones\n",
    "                'popularity': 0.1   # menos peso a popularidad general\n",
    "            }\n",
    "        else:\n",
    "            # Usuario con gustos más variados\n",
    "            return {\n",
    "                'relevance': 0.2,  # menos peso a relevancia específica\n",
    "                'recency': 0.2,    # mantener peso de actualidad\n",
    "                'rating': 0.3,     # mantener peso de valoraciones\n",
    "                'popularity': 0.3   # más peso a popularidad general\n",
    "            }\n",
    "\n",
    "    def explain_weights(self, user_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Genera una explicación en lenguaje natural de los pesos asignados.\n",
    "\n",
    "        Args:\n",
    "            user_id (str): Identificador único del usuario\n",
    "\n",
    "        Returns:\n",
    "            str: Explicación detallada de los pesos y su razón\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            return \"Usuario nuevo: usando pesos por defecto balanceados\"\n",
    "\n",
    "        profile = self.user_profiles[user_id]\n",
    "        genre_diversity = len(profile['genre_preferences'])\n",
    "\n",
    "        explanation = [\n",
    "            f\"Perfil del usuario:\",\n",
    "            f\"- Ha interactuado con {profile['interaction_count']} películas\",\n",
    "            f\"- Tiene preferencias en {genre_diversity} géneros diferentes\",\n",
    "            f\"- Géneros favoritos: {', '.join(sorted(profile['genre_preferences'].keys()))}\",\n",
    "            \"\",\n",
    "            \"Estrategia de personalización:\"\n",
    "        ]\n",
    "\n",
    "        if genre_diversity < 3:\n",
    "            explanation.append(\n",
    "                \"- Mayor peso a relevancia por preferencias específicas\"\n",
    "            )\n",
    "        else:\n",
    "            explanation.append(\n",
    "                \"- Mayor peso a popularidad por gustos variados\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXJ1scI6_J9a"
   },
   "source": [
    "## 4. Fusión Inteligente de Contextos\n",
    "- Genera consultas alternativas automáticamente    \n",
    "- Combina resultados de múltiples fuentes    \n",
    "- Usa pesos dinámicos para la fusión   \n",
    "- Demuestra cómo mejorar la diversidad de resultados   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Sfc-XyWw_Mon"
   },
   "outputs": [],
   "source": [
    "class SmartContextFusion:\n",
    "    \"\"\"\n",
    "    Fusión inteligente de resultados de búsqueda usando múltiples\n",
    "    consultas alternativas y pesos dinámicos.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = 'distiluse-base-multilingual-cased-v1'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def generate_alternative_queries(self, query: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Genera consultas alternativas basadas en la consulta original.\n",
    "\n",
    "        Las consultas generadas cubren diferentes aspectos:\n",
    "        - Consulta original (exactitud)\n",
    "        - Similitud (películas parecidas)\n",
    "        - Calidad (mejores películas)\n",
    "        - Popularidad (películas populares)\n",
    "        - Recomendación (películas recomendadas)\n",
    "\n",
    "        Args:\n",
    "            query (str): Consulta original del usuario\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Lista de consultas alternativas\n",
    "        \"\"\"\n",
    "        alternatives = [\n",
    "            query,  # consulta original\n",
    "            f\"{query} similares\",  # enfoque en similitud\n",
    "            f\"mejores {query}\",  # enfoque en calidad\n",
    "            f\"{query} populares\",  # enfoque en popularidad\n",
    "            f\"{query} más recomendadas\"  # enfoque en recomendación\n",
    "        ]\n",
    "        return alternatives\n",
    "\n",
    "    def get_default_weights(self, num_queries: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Genera pesos por defecto para las consultas alternativas.\n",
    "\n",
    "        Args:\n",
    "            num_queries (int): Número de consultas alternativas\n",
    "\n",
    "        Returns:\n",
    "            List[float]: Lista de pesos normalizados\n",
    "        \"\"\"\n",
    "        if num_queries <= 1:\n",
    "            return [1.0]\n",
    "\n",
    "        # Dar más peso a la consulta original\n",
    "        weights = [0.3]  # consulta original\n",
    "\n",
    "        # Distribuir el resto del peso entre las alternativas\n",
    "        remaining_weight = 0.7\n",
    "        weight_per_query = remaining_weight / (num_queries - 1)\n",
    "        weights.extend([weight_per_query] * (num_queries - 1))\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def fuse_results(self, all_results: List[List[Dict]],\n",
    "                    weights: List[float] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fusiona resultados de diferentes consultas usando pesos específicos.\n",
    "\n",
    "        Args:\n",
    "            all_results: Lista de listas de resultados por cada consulta\n",
    "            weights: Lista de pesos para cada conjunto de resultados\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: Lista de resultados fusionados y ordenados\n",
    "        \"\"\"\n",
    "        if not all_results:\n",
    "            return []\n",
    "\n",
    "        # Usar pesos por defecto si no se proporcionan\n",
    "        if weights is None:\n",
    "            weights = self.get_default_weights(len(all_results))\n",
    "\n",
    "        # Normalizar pesos\n",
    "        weights = np.array(weights) / sum(weights)\n",
    "\n",
    "        # Combinar todos los resultados\n",
    "        combined_scores = {}\n",
    "        for results, weight in zip(all_results, weights):\n",
    "            for result in results:\n",
    "                titulo = result['titulo']\n",
    "                if titulo not in combined_scores:\n",
    "                    combined_scores[titulo] = {\n",
    "                        'score': 0,\n",
    "                        'data': result,\n",
    "                        'found_in_queries': 0,\n",
    "                        'max_individual_score': 0\n",
    "                    }\n",
    "\n",
    "                # Actualizar información del resultado\n",
    "                combined_scores[titulo]['score'] += result['score'] * weight\n",
    "                combined_scores[titulo]['found_in_queries'] += 1\n",
    "                combined_scores[titulo]['max_individual_score'] = max(\n",
    "                    combined_scores[titulo]['max_individual_score'],\n",
    "                    result['score']\n",
    "                )\n",
    "\n",
    "        # Aplicar bonus por aparición en múltiples consultas\n",
    "        for info in combined_scores.values():\n",
    "            query_diversity_bonus = info['found_in_queries'] / len(all_results)\n",
    "            info['score'] *= (1 + 0.2 * query_diversity_bonus)  # 20% bonus máximo\n",
    "\n",
    "        # Ordenar por score combinado\n",
    "        sorted_results = sorted(\n",
    "            combined_scores.values(),\n",
    "            key=lambda x: x['score'],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        return [item['data'] for item in sorted_results]\n",
    "\n",
    "    def explain_fusion(self, titulo: str, combined_scores: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Genera una explicación de por qué un resultado obtuvo su score final.\n",
    "\n",
    "        Args:\n",
    "            titulo (str): Título de la película\n",
    "            combined_scores (Dict): Diccionario con los scores combinados\n",
    "\n",
    "        Returns:\n",
    "            str: Explicación detallada del ranking\n",
    "        \"\"\"\n",
    "        if titulo not in combined_scores:\n",
    "            return f\"No se encontró información para '{titulo}'\"\n",
    "\n",
    "        info = combined_scores[titulo]\n",
    "        explanation = [\n",
    "            f\"Explicación del ranking para '{titulo}':\",\n",
    "            f\"- Encontrada en {info['found_in_queries']} consultas diferentes\",\n",
    "            f\"- Mejor score individual: {info['max_individual_score']:.3f}\",\n",
    "            f\"- Score final combinado: {info['score']:.3f}\"\n",
    "        ]\n",
    "\n",
    "        return \"\\n\".join(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOeB3g_pLn88"
   },
   "source": [
    "## 5. Generador de Respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lno1HuH4LqyJ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class ResponseGenerator:\n",
    "    \"\"\"\n",
    "    Generador de respuestas usando un modelo local pequeño.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "        \"\"\"\n",
    "        Inicializa el generador con un modelo local.\n",
    "        Args:\n",
    "            model_name: Nombre del modelo de HuggingFace a usar.\n",
    "                       Por defecto usa TinyLlama que es ligero pero efectivo.\n",
    "        \"\"\"\n",
    "        print(f\"Cargando modelo {model_name}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,  # usar precisión media para memoria\n",
    "            device_map=\"auto\"  # automáticamente usa GPU si está disponible\n",
    "        )\n",
    "        print(\"Modelo cargado correctamente.\")\n",
    "\n",
    "    def create_context(self, results: List[Dict], max_results: int = 3) -> str:\n",
    "        \"\"\"Crea un contexto estructurado a partir de los resultados.\"\"\"\n",
    "        context_items = []\n",
    "        for i, movie in enumerate(results[:max_results], 1):\n",
    "            context_items.append(\n",
    "                f\"Película {i}:\\n\"\n",
    "                f\"- Título: {movie['titulo']} ({movie['año']})\\n\"\n",
    "                f\"- Género: {movie['genero']}\\n\"\n",
    "                f\"- Descripción: {movie['descripcion']}\\n\"\n",
    "                f\"- Valoración: {movie['valoracion']}/10\"\n",
    "            )\n",
    "        return \"\\n\\n\".join(context_items)\n",
    "\n",
    "    def create_prompt(self, query: str, context: str,\n",
    "                     user_preferences: Optional[Dict] = None) -> str:\n",
    "        \"\"\"Crea un prompt estructurado para el modelo.\"\"\"\n",
    "        base_prompt = f\"\"\"<|system|>\n",
    "Eres un experto en cine que proporciona recomendaciones y análisis de películas.\n",
    "Usa el siguiente contexto para responder la pregunta del usuario.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "{query}\n",
    "\n",
    "<|assistant|>\n",
    "Basándome en las películas mencionadas\"\"\"\n",
    "\n",
    "        if user_preferences:\n",
    "            genres = \", \".join(user_preferences.get('genre_preferences', {}).keys())\n",
    "            base_prompt += f\" y considerando tu interés en {genres},\"\n",
    "\n",
    "        base_prompt += \" te puedo decir que\"\n",
    "        return base_prompt\n",
    "\n",
    "    def generate_response(self, query: str, search_results: List[Dict],\n",
    "                         user_preferences: Optional[Dict] = None,\n",
    "                         max_length: int = 1000) -> str:\n",
    "        \"\"\"Genera una respuesta usando el modelo local.\"\"\"\n",
    "        try:\n",
    "            # Crear contexto y prompt\n",
    "            context = self.create_context(search_results)\n",
    "            prompt = self.create_prompt(query, context, user_preferences)\n",
    "\n",
    "            # Tokenizar\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Generar respuesta\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=max_length,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            # Decodificar y limpiar respuesta\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error al generar respuesta: {str(e)}\"\n",
    "\n",
    "    def generate_specialized_response(self, query: str, search_results: List[Dict],\n",
    "                                    response_type: str) -> str:\n",
    "        \"\"\"Genera respuestas especializadas según el tipo.\"\"\"\n",
    "        try:\n",
    "            context = self.create_context(search_results)\n",
    "\n",
    "            type_instructions = {\n",
    "                'recommendation': \"\"\"\n",
    "                Genera una recomendación personalizada de estas películas.\n",
    "                Explica por qué cada película podría ser interesante.\n",
    "                \"\"\",\n",
    "                'analysis': \"\"\"\n",
    "                Proporciona un análisis detallado de las películas mencionadas.\n",
    "                Incluye elementos narrativos y temas principales.\n",
    "                \"\"\",\n",
    "                'comparison': \"\"\"\n",
    "                Compara las películas mencionadas, destacando similitudes\n",
    "                y diferencias en género, estilo y temas.\n",
    "                \"\"\"\n",
    "            }\n",
    "\n",
    "            prompt = f\"\"\"<|system|>\n",
    "{type_instructions.get(response_type, type_instructions['recommendation'])}\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "{query}\n",
    "\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "            return self.generate_response(prompt, search_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error al generar respuesta especializada: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmdezvYV_O-t"
   },
   "source": [
    "## 5. EJEMPLO DE USO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYzB1KZC_UdX"
   },
   "source": [
    "### Datos de Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "METAJPQVDl0L"
   },
   "source": [
    "Simulamos datos de películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zcwnmRyt_W6y"
   },
   "outputs": [],
   "source": [
    "movies_data = {\n",
    "    'titulo': [\n",
    "        'El Padrino',\n",
    "        'Matrix',\n",
    "        'Inception',\n",
    "        'La La Land',\n",
    "        'Get Out',\n",
    "        'Interestelar',\n",
    "        'El Señor de los Anillos',\n",
    "        'Parásitos',\n",
    "        'Whiplash',\n",
    "        'Coco',\n",
    "        'Mad Max: Fury Road',\n",
    "        'El Gran Hotel Budapest',\n",
    "        'Black Panther',\n",
    "        'Wonder Woman',\n",
    "        'Arrival',\n",
    "        'Ex Machina',\n",
    "        'Your Name',\n",
    "        'El Laberinto del Fauno',\n",
    "        'Ciudad de Dios',\n",
    "        'Amelie'\n",
    "    ],\n",
    "    'descripcion': [\n",
    "        'Una familia mafiosa en Nueva York lucha por mantener su imperio criminal',\n",
    "        'Un programador descubre que la realidad es una simulación computarizada',\n",
    "        'Un ladrón especializado se infiltra en los sueños de sus objetivos',\n",
    "        'Una aspirante a actriz y un músico de jazz persiguen sus sueños en Los Ángeles',\n",
    "        'Un joven afroamericano visita a la familia de su novia con inquietantes consecuencias',\n",
    "        'Un grupo de astronautas busca un nuevo hogar para la humanidad',\n",
    "        'Un hobbit debe destruir un anillo mágico para salvar la Tierra Media',\n",
    "        'Una familia pobre se infiltra en la vida de una familia rica',\n",
    "        'Un joven baterista persigue la perfección bajo un instructor implacable',\n",
    "        'Un niño viaja al mundo de los muertos durante el Día de los Muertos',\n",
    "        'En un mundo post-apocalíptico, una guerrera lidera una rebelión',\n",
    "        'Las aventuras de un legendario conserje de hotel en la Europa de entreguerras',\n",
    "        'El príncipe de Wakanda debe defender su reino y su legado',\n",
    "        'Una princesa amazona se convierte en una poderosa superheroína',\n",
    "        'Una lingüista intenta comunicarse con alienígenas recién llegados',\n",
    "        'Un programador participa en un experimento de inteligencia artificial',\n",
    "        'Dos adolescentes japoneses intercambian cuerpos misteriosamente',\n",
    "        'Una niña descubre un mundo mágico durante la posguerra española',\n",
    "        'El crecimiento del crimen organizado en las favelas de Río',\n",
    "        'Una camarera parisina decide ayudar a mejorar la vida de otros'\n",
    "    ],\n",
    "    'genero': [\n",
    "        'Drama, Crimen',\n",
    "        'Sci-Fi, Acción',\n",
    "        'Sci-Fi, Thriller',\n",
    "        'Musical, Romance',\n",
    "        'Terror, Thriller',\n",
    "        'Sci-Fi, Drama',\n",
    "        'Fantasía, Aventura',\n",
    "        'Drama, Comedia',\n",
    "        'Drama, Música',\n",
    "        'Animación, Fantasía',\n",
    "        'Acción, Aventura',\n",
    "        'Comedia, Drama',\n",
    "        'Acción, Aventura',\n",
    "        'Acción, Fantasía',\n",
    "        'Sci-Fi, Drama',\n",
    "        'Sci-Fi, Drama',\n",
    "        'Animación, Romance',\n",
    "        'Fantasía, Drama',\n",
    "        'Drama, Crimen',\n",
    "        'Comedia, Romance'\n",
    "    ],\n",
    "    'año': [1972, 1999, 2010, 2016, 2017, 2014, 2001, 2019, 2014, 2017, 2015, 2014, 2018, 2017, 2016, 2015, 2016, 2006, 2002, 2001],\n",
    "    'valoracion': [9.2, 8.7, 8.8, 8.5, 7.7, 8.6, 8.8, 8.6, 8.5, 8.4, 8.1, 8.1, 7.3, 7.4, 7.9, 7.7, 8.4, 8.2, 8.6, 8.3],\n",
    "    'popularidad': [100, 95, 90, 85, 80, 88, 98, 87, 82, 89, 86, 83, 92, 88, 84, 81, 85, 84, 87, 86]  # índice de popularidad\n",
    "}\n",
    "df = pd.DataFrame(movies_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql_j2Mzo_f88"
   },
   "source": [
    "###5.1 Búsqueda Semántica Mejorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711,
     "referenced_widgets": [
      "27e86f91c9c44551b61018596573b677",
      "8e0bbc583b0d4ebfa56abf2d4fd58cc7",
      "6113a3f0864849c99c2bb658c0106e73",
      "203b5ab228c84dfd85e86a348c34eead",
      "38b4bbc239cd4b5480c57ddfb91d9fc1",
      "361ddaa3075b4eff81fcd94cc51a96f1",
      "8ea4eee427da498d8be149da40d50e47",
      "a61e1f227e4e4e71bb675f7c793ab076",
      "ffa855333ff148d7b32bc02bfe08d984",
      "6ab9c176ac834bceb0da16418cf8c9cb",
      "5c7d7f2fc13c47909d0e014e2c56edf5",
      "58a47c0642a54bd0b5ad8571ea8478e0",
      "d12e080a541448288364c3128e040888",
      "d04ea886ec754db1bd9432d37515484a",
      "c1c89c37918e47beb6466e2a729a90ed",
      "5a7191930e184905853ff209bfa197e3",
      "9f2814cfb95d422e93246a4fc0133d53",
      "8465ad4186a04be986da1d948785e6c3",
      "eaf9c1ad28944c87a893ae6cd985fce4",
      "db0a6a81fa8e45b986f3ae582195a723",
      "18f2eb9166c14486aaf23d5f3a7925a3",
      "baa6fba9157b47a1b245b9ed81907af4",
      "d14d47261a8641069036c45dd3e5b5d3",
      "d34e3c519736488e8219d18c3e41d603",
      "29a4701c45e14086a0ee8dc3ee47a08c",
      "92b7d5d7110148eead64a3e696c84ac0",
      "9ab85d7a0fec48368f4592b68f2dbfbc",
      "1fc6d60cd54a49eca6392adada3e955f",
      "d128a81e37834e02af98d76f2a6e5339",
      "30fc8a52da0a4467a2b5e1f8523b4406",
      "13a50059aac64139866031897a730a1c",
      "c505091e90fb44058af160b7f73653ef",
      "f2b30e14081c40428493b907c6691999",
      "fa38090c10ac455bbee2a99f839e8d1e",
      "ad359d3985984635816c4827576c612d",
      "e6893fe138fc4bb4b14350d917f4f765",
      "96a471e738a1474793f5553072f934e8",
      "dd231f9661164a65993388947a91b8aa",
      "0963d1c6330f48ef9ed5c8ea61ed93f9",
      "f0db7863814a4bf49ee832cb4ef29743",
      "0d017b6a4dee456db58d5b205243df8f",
      "389659467e904b468a54eef63dd2fa7c",
      "0d522d99329a42b18d6b642b2baee091",
      "db86b794d4e74b009dc3995c6004a467",
      "5bae270e22544cbd841f64ddb42faa6f",
      "1fc164d9ba8e471dafdd3411751e6afa",
      "16dc23061e564993993697d9deafa08b",
      "feab588de6874e518d5228b4e7c0f6fe",
      "0db7fb32aa7643f080e9779675a46ce1",
      "b54c671ccc4942438518b03b7315b561",
      "67dc528801a447aeb87abdd5956705ee",
      "59f942f6eddd4295bc1393d63445ca5f",
      "8ef11b77a362411286261df72d66cc67",
      "aa054b9ac0f44224a96ab428a6d1a67c",
      "dabc229d0f7847f1a8c683266d270c12",
      "426ea1e51b5949a2837a62686d887ebe",
      "54741f3abf114753b76363a6cc62db2e",
      "8e4cdd66cd5b4311aae17c330c993be0",
      "ff52cc1b555142b1b05eee67aeb9868e",
      "472b99f7baca4790a5d9bae509b1714f",
      "3bfeccf010dd457eb98c91d150cc35ca",
      "a8da336774fd4f5f816e567151eeed33",
      "00b3cb0ca206432bb316c1357fa9beac",
      "3771278f64cf4241b9a66215e217d724",
      "6828c5941f0946b2b92b55b857a71830",
      "8e9d92160a86434e883b2d71f9728feb",
      "398026f81c054c4a85756d81012044ce",
      "8e10da6e1f484e809d852f1fff2a3a12",
      "f08bfb890f004b6da19ea7266c0ef627",
      "f7a599aaf90948689500c307e2db3be5",
      "b102822445ef474db24f101baddc543a",
      "a811d2ff3d1147bd88485eb4ef907dae",
      "80aa1553e64f4fcfb1782e9f2c9ad2d2",
      "77ecc36775ee44daa4ebb6c1aaa515d4",
      "e6a09062e1e34389994ac1d8c9fe2fcc",
      "8eb08934bd9c4928aebf5fbf51151418",
      "bc9e559df40c4d79b28d791143675714",
      "58241eba59a04bf5838b6ccd0d4ab51f",
      "3397954d321042a899f210dd7e3e478a",
      "7573668133d04271a0468d1da9383e0b",
      "d7cf9b075c0348fc94e2b87a8f178ee2",
      "616df95f09b7425695c01141d0b32c3e",
      "c7739319d177413484d74f178f3e179d",
      "483ef19fcddc449281e7c40bfdb41e34",
      "d550f4ecfc08490f931720513555ebfa",
      "0b8b3cd67b084a9189ce0101172c4df6",
      "6ab06adc976d42d09e34e739ba61575f",
      "40180a52be414ccf8e97e02549f4b608",
      "27d70ec6e24e446eaef52172d91d0604",
      "ce715d333cf54fc9a9068d49e310b793",
      "cfae5bbc92784d3f855c13aea75aad1c",
      "184dfddf80aa49378c3d46e893e27fde",
      "7e42657427e64b549ea7a1fe2c817d45",
      "a317e0ca2412403ca82d5924fe852b41",
      "67665ac82f394a789cfd3bb3837ad966",
      "255798b24b6b4af5bdcc4525f20f7083",
      "e9e9d976bc834a7c92ecfe166d58e212",
      "1f9c24e30de64c439c46056b15c72835",
      "45606f66393249d981b5ac35a1ad4bdb",
      "bdf7c0dcdcb84551832c90b131e3b606",
      "b339d7c52cf94ec1816f444483d0d6a0",
      "6df9587caf4a44229c8bfbe9cae0e41e",
      "6995c43014174a12a5b806dbf4394088",
      "f3101b97bab54153ae8e1d7781944bfa",
      "b1cde7900d294655b7ac5387e81dc636",
      "c52c059d27c543b285988881629e367c",
      "25be3d1b39b047e4921e9046e42e809f",
      "99f2ddf7a240448cb547d567e0ed2cb1",
      "8aaf737824c6419d9d335c71d40d284a",
      "285fd520a4fc45e89002be259e743e8b",
      "b4ba496b466d420197bae4f8d25f9661",
      "09e4376992cb4668b76cd41108f8b1f1",
      "2bc69f0f39ad42d79896704dd2373999",
      "7140b17abee34e83a20c2a93480c3ae6",
      "29373416dad34f658e5c10921d8851a9",
      "b26c2c67b64946c2a19245c34202c0fe",
      "e77273e89277475bb3f680020f606334",
      "1271990545da4e0998576c3146955137",
      "8d104e83b83147d0b4dbded757c0c0ee",
      "0eb09e772e2244a783e752525b498251",
      "b7851f3ff2df43ff974345d6a5294f05",
      "bf55179472094b21b28ef5f8503df625",
      "fc536f7fc63944a584320a46690b79f9",
      "91ae4d37e10c48ab8b71968eb8bc7658",
      "dd7ce0fc8cc041f59905603c0da07f9e",
      "d0f4f7d5827d4adb842e2fb80e40b41e",
      "41ded50c14ca4b7b8acd27c0f8db50a6",
      "ce6ecfce84a54b02973e48ebb951d637",
      "698b8ab77a28470ea5715f4b8a5def36",
      "e9be8e6a52d64e95bb6216a06c400577",
      "ccfecb6311054b4582cd5e8bb35793d4",
      "4618a4adb7e14b16bf49a59dedc62b5f",
      "584cb9499a034e1e90202fee27e797e9",
      "aa297662ecff49ce892b6a0af5407e6e",
      "d0647a70c99b41fc961cda4c564d5197",
      "1e02324c41da4c5e9720a00d6d213ef1",
      "44571ae4999643f3a0c1fe4bc8e4c222",
      "91e4c7a547e8457c882e017937ee5fb8",
      "f0e926daae974298b838cb029e152886",
      "13875f9d064d4f228dfbe07c7ff84e40",
      "5f40bea194774f109af61a54421566ac",
      "728ff3dc8d43471e9fe52743f683baaf",
      "6423244055d44ea489c43801830aa134",
      "076de4d0b4254526b64ad489e31ca453",
      "33e456c82cad473ea71c836c1dc7eb4e",
      "57e36edb18254850bbd488391c5ed9cf",
      "1c85fd2d45614db290f6113203125014",
      "7e465c4caf0848b4a7fa88e975b3a0d2",
      "448fb27d4e424c27bc8cfe56b7ade167",
      "1c478d6bad074712bc8b2d9357baf973",
      "7477f5a35c94482a8cc76a0a41f17218",
      "39b18b7dc78c4dcfa832e38eee94074c",
      "546aa07557db4d339111418d6f27b843",
      "6c59ec70f0d142b687edfb716336fe02"
     ]
    },
    "id": "0qI-JNm-_RbB",
    "outputId": "23897e99-5c7d-4cce-d6dc-1b74c6946b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Probando Búsqueda Semántica Mejorada...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e86f91c9c44551b61018596573b677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a47c0642a54bd0b5ad8571ea8478e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14d47261a8641069036c45dd3e5b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa38090c10ac455bbee2a99f839e8d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bae270e22544cbd841f64ddb42faa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/556 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426ea1e51b5949a2837a62686d887ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398026f81c054c4a85756d81012044ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/452 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58241eba59a04bf5838b6ccd0d4ab51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d70ec6e24e446eaef52172d91d0604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf7c0dcdcb84551832c90b131e3b606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ba496b466d420197bae4f8d25f9661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf55179472094b21b28ef5f8503df625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584cb9499a034e1e90202fee27e797e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076de4d0b4254526b64ad489e31ca453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings de sinopsis...\n",
      "Generando embeddings de keywords...\n",
      "0 {'titulo': 'Inception', 'descripcion': 'Un ladrón especializado se infiltra en los sueños de sus objetivos', 'genero': 'Sci-Fi, Thriller', 'año': 2010, 'valoracion': 8.8, 'popularidad': 90, 'score': 0.43998563}\n",
      "1 {'titulo': 'Interestelar', 'descripcion': 'Un grupo de astronautas busca un nuevo hogar para la humanidad', 'genero': 'Sci-Fi, Drama', 'año': 2014, 'valoracion': 8.6, 'popularidad': 88, 'score': 0.43668205}\n",
      "2 {'titulo': 'Arrival', 'descripcion': 'Una lingüista intenta comunicarse con alienígenas recién llegados', 'genero': 'Sci-Fi, Drama', 'año': 2016, 'valoracion': 7.9, 'popularidad': 84, 'score': 0.43103325}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "query = \"películas de ciencia ficción\"\n",
    "print(\"\\n1. Probando Búsqueda Semántica Mejorada...\")\n",
    "enhancer = SemanticSearchEnhancer()\n",
    "enhancer.prepare_data(df)\n",
    "semantic_results = enhancer.search(query, df)\n",
    "for idx, result in enumerate(semantic_results):\n",
    "  print(idx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TNWFA7G_zl8"
   },
   "source": [
    "###5.2 Re-ranking Contextual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IN0FDh7O_4pp",
    "outputId": "c85aa769-0db0-40a8-d7ef-f08f535074f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Probando Re-ranking Contextual...\n",
      "\n",
      "Ranking para 'Inception':\n",
      "- Relevancia semántica: 0.440\n",
      "- Factor de actualidad: 0.400\n",
      "- Valoración usuarios: 0.880\n",
      "- Índice popularidad: 1.000\n",
      "Score final: 0.836\n",
      "\n",
      "Ranking para 'Interestelar':\n",
      "- Relevancia semántica: 0.437\n",
      "- Factor de actualidad: 0.476\n",
      "- Valoración usuarios: 0.860\n",
      "- Índice popularidad: 0.978\n",
      "Score final: 0.826\n",
      "\n",
      "Ranking para 'Arrival':\n",
      "- Relevancia semántica: 0.431\n",
      "- Factor de actualidad: 0.526\n",
      "- Valoración usuarios: 0.790\n",
      "- Índice popularidad: 0.933\n",
      "Score final: 0.785\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Probando Re-ranking Contextual...\")\n",
    "reranker = ContextualReranker()\n",
    "\n",
    "# Definir pesos personalizados para el re-ranking\n",
    "contextual_weights = {\n",
    "    'relevance': 0.1,\n",
    "    'recency': 0.1,\n",
    "    'rating': 0.4,\n",
    "    'popularity': 0.4\n",
    "}\n",
    "\n",
    "reranked_results = reranker.rerank(semantic_results, contextual_weights)\n",
    "\n",
    "# Mostrar explicaciones del ranking\n",
    "for result in reranked_results:\n",
    "    print(\"\\n\" + reranker.explain_ranking(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e41Bbpns_747"
   },
   "source": [
    "###5.3 Personalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkP2OdNK__q-",
    "outputId": "66290186-6dc3-43d0-faac-7310e72488a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfil del usuario:\n",
      "- Géneros favoritos: {'Sci-Fi': 2, 'Drama': 2, 'Acción': 1}\n",
      "- Películas que le gustaron: ['Interestelar', 'Matrix', 'Whiplash']\n",
      "- Búsquedas recientes: ['mejores películas de ciencia ficción', 'películas con efectos especiales']\n",
      "\n",
      "2. PESOS PERSONALIZADOS\n",
      "=======================\n",
      "\n",
      "Pesos calculados según el perfil:\n",
      "- relevance: 0.20\n",
      "- recency: 0.20\n",
      "- rating: 0.30\n",
      "- popularity: 0.30\n",
      "\n",
      "3. Probando Personalización...\n",
      "\n",
      "Ranking para 'Interestelar':\n",
      "- Relevancia semántica: 0.437\n",
      "- Factor de actualidad: 0.476\n",
      "- Valoración usuarios: 0.860\n",
      "- Índice popularidad: 0.978\n",
      "Score final: 0.734\n",
      "\n",
      "Ranking para 'Inception':\n",
      "- Relevancia semántica: 0.440\n",
      "- Factor de actualidad: 0.400\n",
      "- Valoración usuarios: 0.880\n",
      "- Índice popularidad: 1.000\n",
      "Score final: 0.732\n",
      "\n",
      "Ranking para 'Arrival':\n",
      "- Relevancia semántica: 0.431\n",
      "- Factor de actualidad: 0.526\n",
      "- Valoración usuarios: 0.790\n",
      "- Índice popularidad: 0.933\n",
      "Score final: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Simulamos un perfil de usuario con preferencias\n",
    "personalizer = PersonalizationEngine()\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Simular historial del usuario\n",
    "historial_usuario = [\n",
    "    {'genero': 'Sci-Fi, Drama', 'liked_movie': 'Interestelar'},\n",
    "    {'genero': 'Sci-Fi, Acción', 'liked_movie': 'Matrix'},\n",
    "    {'query': 'mejores películas de ciencia ficción'},\n",
    "    {'genero': 'Drama', 'liked_movie': 'Whiplash'},\n",
    "    {'query': 'películas con efectos especiales'}\n",
    "]\n",
    "\n",
    "# Actualizar perfil con el historial\n",
    "for interaccion in historial_usuario:\n",
    "    personalizer.update_profile(user_id, interaccion)\n",
    "\n",
    "# Mostrar preferencias actuales\n",
    "print(\"\\nPerfil del usuario:\")\n",
    "preferencias = personalizer.get_user_preferences(user_id)\n",
    "print(f\"- Géneros favoritos: {dict(preferencias['favorite_genres'])}\")\n",
    "print(f\"- Películas que le gustaron: {preferencias['liked_movies']}\")\n",
    "print(f\"- Búsquedas recientes: {preferencias['recent_searches']}\")\n",
    "\n",
    "print(\"\\n2. PESOS PERSONALIZADOS\")\n",
    "print(\"=======================\")\n",
    "user_weights = personalizer.get_personalized_weights(user_id)\n",
    "print(\"\\nPesos calculados según el perfil:\")\n",
    "for factor, peso in user_weights.items():\n",
    "    print(f\"- {factor}: {peso:.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\n3. Probando Personalización...\")\n",
    "reranked_results = reranker.rerank(semantic_results, user_weights)\n",
    "\n",
    "# Mostrar explicaciones del ranking\n",
    "for result in reranked_results:\n",
    "    print(\"\\n\" + reranker.explain_ranking(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DzWLRdCAGHs"
   },
   "source": [
    "### 5.4. Fusión de Contextos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHUjE-ouAKAN",
    "outputId": "0136d94d-6648-4e67-e594-48842bae7d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Probando Fusión de Contextos...\n",
      "\n",
      "Consulta original: 'películas de ciencia ficción'\n",
      "Consulta alternativa: 'películas de ciencia ficción similares'\n",
      "Consulta alternativa: 'mejores películas de ciencia ficción'\n",
      "Consulta alternativa: 'películas de ciencia ficción populares'\n",
      "Consulta alternativa: 'películas de ciencia ficción más recomendadas'\n",
      "0 {'titulo': 'Inception', 'descripcion': 'Un ladrón especializado se infiltra en los sueños de sus objetivos', 'genero': 'Sci-Fi, Thriller', 'año': 2010, 'valoracion': 8.8, 'popularidad': 90, 'score': 0.43998563}\n",
      "1 {'titulo': 'Interestelar', 'descripcion': 'Un grupo de astronautas busca un nuevo hogar para la humanidad', 'genero': 'Sci-Fi, Drama', 'año': 2014, 'valoracion': 8.6, 'popularidad': 88, 'score': 0.43668205}\n",
      "2 {'titulo': 'Arrival', 'descripcion': 'Una lingüista intenta comunicarse con alienígenas recién llegados', 'genero': 'Sci-Fi, Drama', 'año': 2016, 'valoracion': 7.9, 'popularidad': 84, 'score': 0.43103325}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Probando Fusión de Contextos...\")\n",
    "fusion = SmartContextFusion()\n",
    "\n",
    "print(f\"\\nConsulta original: '{query}'\")\n",
    "\n",
    "alt_queries = fusion.generate_alternative_queries(query)\n",
    "for query_generada in alt_queries[1:]:\n",
    "    print(f\"Consulta alternativa: '{query_generada}'\")\n",
    "all_results = [enhancer.search(q, df) for q in alt_queries]\n",
    "final_results = fusion.fuse_results(all_results)\n",
    "for idx,result in enumerate(final_results):\n",
    "  print(idx, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_gfWj4ELx2T"
   },
   "source": [
    "###5.5 RAG de Películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764,
     "referenced_widgets": [
      "aac7415c1cfc45c3bb615e8802aec1ba",
      "56cfbb6f874347459adb95b26ae03fa3",
      "98d31d3ca96344dab88a2fd794a3f92b",
      "6d0f42237169420e8e9eec20f2b653b9",
      "42ad6aa98f6c40b1a3ff0293271afe99",
      "8aa250b4211b4d6eada667c32447474c",
      "f572c17cbfd04d088de67f2173e0c772",
      "a1b51e938f19445c828e429a9ace974a",
      "0eb19d588d4e4895b1d4b458204b5795",
      "cc6f32e1d96f4762926982ef45398a14",
      "17d4aa2083b24ed586ffce359adf6d93",
      "55b438f54e1a4058b05d0551bd3c75bb",
      "fbed08544c8b43beb8ebf7396408cbd8",
      "9325f7a4610142258a8c339bda47a330",
      "3bc03fd71134457bb13a95bc873b051e",
      "545f0b05374e4cc691b9dc07e8d2037b",
      "0c678c3e15e84069b57c86c369f4a595",
      "a89bad2be50344ef98adc068fe2f2f32",
      "2b42a66b54f6412ebe8bf7841eb6cb7d",
      "71fb8810f98d43c9a426c10206ec35ce",
      "bd8dc3b49caf4b7db909bdc950cb602b",
      "6d7e651737504dc6b4ee0949e4ae3192",
      "107b3269ca2e42b6b64fac3ec36e558f",
      "fe573495d673410590494d632038b52d",
      "4dc67d60721447968ef0dac2f701b2dc",
      "d9cfa473f0864c369846e695dac28303",
      "b9002f757ac14b8aa2e08b02424c237e",
      "c9cc480b4a4546b792d4ddfba6870729",
      "56e70b497f8e442c9afeb3620a3e5579",
      "8cec878df3344dfb817f2d8df0f0cfa0",
      "49b2825fb429490bb0ee954d19982698",
      "43fcefd4e69b47da97b55588f3e5cbae",
      "da30815f4e8e405ab44ddfa4df8e4ad2",
      "6914521c426244febf57ebcc3a7f3e56",
      "6e4b255eb6e24071b5fa59a0deeddab6",
      "9339fcb0aa1c46588cd71eb7d21fb495",
      "ea2b979a793c46c39742f5f3c14b6240",
      "b073c027eb754f17bf2369610b154da6",
      "22e331a59dd24b6ca11f1637ac46fec9",
      "bf0d94aa8ea8436fa92d14f3178904ed",
      "c1d1551482cd4bfd900bf8e446112291",
      "c80e1907a9e14f8a81c1c516992d72ce",
      "503021f47f004c64aceb7f181d489ef6",
      "0a68fb31d61043a2b19451772a61519d",
      "cdc3c74294e24074b2568af1c449e86c",
      "ab26c40bffd542048d8536cf9c50ab8c",
      "3e0519b3e35b46d4af48f69392c475bc",
      "abdda7c16d224d10b79dccb30321311a",
      "021aa207d3a4458a93dad647f060e3b8",
      "e2498bd9d93349448e1019f00d47854c",
      "2c62c343d7f04c3c936386d92f9ec400",
      "fbe513718cca4714b0b61a5bffc6ec83",
      "24a3f09e958941e093e1269c4ddacbbc",
      "676dce0891fc4d4ba77d8c0e87811c2b",
      "351e7287a1484e419b56954a9e648aa7",
      "be4df84a40ad4045b3fdfcacf994ac10",
      "251c4d239d714a55a023d964d39aa7e5",
      "868066bdd74b43debb87337d1c75e4dc",
      "71d9c3eb8ec141aca8f6f1eafb9b63cd",
      "45c9c0b57dd34be3a0498fd5ea82a5a0",
      "7cc25f31b9e7408582af788bcfb1990a",
      "c4ad95a7cfb640bb8c468b62a2ab822c",
      "93f61ee99b3440af96dcecd3378f21ee",
      "23195633958b46b1b651bfdd5a176949",
      "5dd0ddf7f0c64d6c9b6c908d8b133a4a",
      "fe4819d4ffa94afc9c3d3803f3de9484",
      "03455025611f4158bcea8b83eabb1824",
      "626361804fae427791f67f40c754ba7d",
      "bc0f477919d843558e0ea8105cb1a325",
      "400cff91e725448096a0cb117c040014",
      "fe0ad50cc5df4aa1bf908f280a406d4f",
      "bcee055e78be4649bf9f20e7cb7b625d",
      "aa4a69c48f384a4c8c6dbf747cb5a559",
      "11047669c2a4484fbd9a3c5f771164ca",
      "19c260e6d1f0482497fc3a1840f0507e",
      "8ec32d802be14481b22164b6bf5cc3e6",
      "3323c978bdc1481a8c6a461f7dac37a4"
     ]
    },
    "id": "_7EjE4tcL-hX",
    "outputId": "b6ad9891-12de-4319-aaea-31e8decfe923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac7415c1cfc45c3bb615e8802aec1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b438f54e1a4058b05d0551bd3c75bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b3269ca2e42b6b64fac3ec36e558f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6914521c426244febf57ebcc3a7f3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3c74294e24074b2568af1c449e86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4df84a40ad4045b3fdfcacf994ac10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03455025611f4158bcea8b83eabb1824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n",
      "Consulta: películas de ciencia ficción\n",
      "\n",
      "Generando recomendación personalizada...\n",
      "\n",
      "Recomendación generada:\n",
      ":\n",
      "\n",
      "1. Inception (2010): es un thriller de ciencia ficción que presenta una lógica mágica en su trama, con el uso de técnicas de la cineografía de gran calidad y una excelente actuación de Leonardo DiCaprio como protagonista.\n",
      "\n",
      "2. Interestelar (2014): es una película de ciencia ficción que aborda temas como el espacio exterior y la evolución del universo, con una gran actuación de Amy Adams como la principal protagonista.\n",
      "\n",
      "3. Arrival (2016): es una película de ciencia ficción que ofrece una visión de la cultura extraterrestre y la paz, con una actuación de Amy Adams como la protagonista.\n",
      "\n",
      "aunque no es la única película en la lista, estas son las que me han interesado más en el tema de ciencia ficción. Por su parte, si te interesa más películas de ciencia ficción, puedes consultar mi lista de películas de ciencia ficción.\n",
      "\n",
      "Generando análisis detallado...\n",
      "\n",
      "Análisis de películas:\n",
      ":\n",
      "\n",
      "1. Inception (2010): Esta película es un éxito de taquilla y tiene una valoración de 8,8/10 en la página de Rotten Tomatoes. Su temática principal es la de la invención de la realidad y cómo una ladrón especializado se infiltra en los sueños de sus objetivos para conseguir la información necesaria para la invención.\n",
      "\n",
      "2. Interestelar (2014): Esta película es un éxito de taquilla y tiene una valoración de 8,6/10 en la página de Rotten Tomatoes. Su temática principal es la de la nave espacial y cómo una ladrón especializado intenta comunicarse con los alienígenas para obtener información.\n",
      "\n",
      "3. Arrival (2016): Esta película es un éxito de taquilla y tiene una valoración de 7,9/10 en la página de Rotten Tomatoes. Su temática principal es la de la comunicación con los extraterrestres y cómo una lingüista intenta comunicarse con ellos.\n",
      "\n",
      "Con respecto a los elementos narrativos y temas principales, las películas mencionadas tienen una historia central que se centra en la invención de la realidad y cómo se logra la información necesaria para la misma. Además, cada película también tiene temas relacionados con la nave espacial y la comunicación con otros planetas o extraterrestres.\n"
     ]
    }
   ],
   "source": [
    "generator = ResponseGenerator()\n",
    "print(\"Consulta:\",query)\n",
    "print(\"\\nGenerando recomendación personalizada...\")\n",
    "response = generator.generate_response(\n",
    "    query=query,\n",
    "    search_results=final_results,\n",
    "    user_preferences=preferencias\n",
    ")\n",
    "print(\"\\nRecomendación generada:\")\n",
    "print(response)\n",
    "\n",
    "# Generar análisis\n",
    "print(\"\\nGenerando análisis detallado...\")\n",
    "analysis = generator.generate_specialized_response(\n",
    "    query=query,\n",
    "    search_results=final_results[:3],\n",
    "    response_type='analysis'\n",
    ")\n",
    "print(\"\\nAnálisis de películas:\")\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNEQCxknINPKBxD0O1mtc8t",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
