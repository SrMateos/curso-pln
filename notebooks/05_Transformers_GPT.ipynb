{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/05_Transformers_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B7RyMVTtO4F"
   },
   "source": [
    "# Generación de Texto usando Transformers\n",
    "\n",
    "Este notebook demuestra cómo usar modelos Transformer para generar texto en español.\n",
    "\n",
    "Utilizaremos el modelo GPT2 específicamente ajustado para español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsjy7JKGtTuq"
   },
   "source": [
    "##1) Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j5y3x4J9tYes"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywi3ROQ2to9I"
   },
   "source": [
    "##2) Cargar el modelo y tokenizador\n",
    "Usamos 'datificate/gpt2-small-spanish', un modelo más ligero entrenado para español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "c0677c3bee314fbeb02022bac86ff725",
      "9ea26fd8dd1b464599d9e6a2cbd387e0",
      "653dffd28ed447418f506070859aa0ec",
      "d3485cf1185d42fda9e16bd5c83d4179",
      "840d386d2d7e41068aba61ca136d98f4",
      "a4ff56f923f04d6caaaae5a09c150d32",
      "32a1aecc1e61424281c82cfede04de7d",
      "527d6be094d2461faf36b85b1d448344",
      "aec596dd5cbb474785b9c88ecfc92519",
      "b019b275b94c4a178d288943d8752675",
      "cf2dd7166c604aea89ec8540043eaf5a",
      "583fc264e5d74be099fe41b28a47f473",
      "7cb3a17510a245248ee5a5b7dbbdde80",
      "d842ce015a184b1ab33b8bbb58dce58f",
      "89a4a8507ae44705b4b62cdfb43a4a5c",
      "f517b0327d6640c48572be31ab400202",
      "d83ec5868e454986b7faad77b9a519b8",
      "156842b141bf4fc4b2ad6d11b2f648d4",
      "475f133c389144d9b2b2e327bd8426f4",
      "47f7c0378f684685a636eb72a92dceb5",
      "586086c352cd49daada17262da817f07",
      "56605721827243abbfedcdbe82163bbd",
      "6443e761d6584e68b76c49de93ae95e4",
      "6411f686eaea433a977414a156f8ccd3",
      "9e2ed4c402f44ee791d4ca6f7130117b",
      "c1d91f30eaa14714bde2f97e75212768",
      "b6260aee374246a5b020ebf59b910e11",
      "cd2831712132409e920e27e183f2a5f2",
      "3a140fede2c149d79e05710f0483e93f",
      "28ec1510a383422ea9cb8e9eb22165cf",
      "465c3d9219fc423bbd3279e190644d61",
      "882f25ceaa21451ca0caaffc91c6ce6b",
      "a9c61c374c2b4de3963d6fcffc20eb10",
      "31f2cde590f449f19267bfa3003867c2",
      "a267dd95ea974a2a9e55cf7228ef13af",
      "717b01efade84812b1be811559aaa1fa",
      "f026a6f3a9384611955162351bc193cf",
      "01329b0bc5d24fd7b01e82ea61e18b68",
      "8e81dd452b574c05ba8a7795b1850d44",
      "2d85323918b6402d91d1d5799b15ee04",
      "05f7e6b5c3d944fb876b561b87218243",
      "706982011ca84ca58aef83b9c7e426e9",
      "9a1503b483fb41b788872b9f05be2d4a",
      "93f74426f7234b5abdbd42e1249d0587",
      "08d92d66a2114b54a9e5db73b8125177",
      "040921253db347f0afb58c18c162fbc2",
      "5180fc0bb35047a39a7c85bd7800ac1d",
      "cb92d0973dc646458e1bb8b793f71c13",
      "e22e3f04b4194e76a3825a5d6e6bdb26",
      "fad461609f9648ae99d8e6302a730a3b",
      "e1f740c6c0fb4c48ae5cb5330601e3bb",
      "709c6765bda1463fb5d84f5f9daf261a",
      "747bc6621c2c466da8965dd149ba827f",
      "b85062977a9a4762842c902685953848",
      "42795088e5144b5da1a613d36d292031",
      "80ab8a58899f4d5eb1ba4950e4321167",
      "dd20783e4df548b499a13ec82d5dec9d",
      "13403829eb0a4b89a68f84fe187906b4",
      "a8d9a6e601c8487a9308de7383fb2194",
      "48ae694a1e534158b883bfc28b0ea0ad",
      "8d90a1a043df4de4812d2cf8acc05fb9",
      "83098697ddaa4c538ebd448481ccf342",
      "47744ef9da51497ba274c6f7e55562c6",
      "142034b61f364dd9b77b96d9218ce156",
      "0954da54e4e048c5aec12fa8bfcad8e0",
      "d2226eb01893456ba7df734c8d434b88"
     ]
    },
    "id": "GL6sAxvKtr2E",
    "outputId": "59ccd850-8ca9-41b9-f0f4-81c57aed7242"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0677c3bee314fbeb02022bac86ff725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583fc264e5d74be099fe41b28a47f473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/817 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6443e761d6584e68b76c49de93ae95e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/850k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f2cde590f449f19267bfa3003867c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/508k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d92d66a2114b54a9e5db73b8125177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ab8a58899f4d5eb1ba4950e4321167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"datificate/gpt2-small-spanish\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFI-l-pVtueF"
   },
   "source": [
    "##3) Función para generar texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ASxxcHx6tzTZ"
   },
   "outputs": [],
   "source": [
    "def generar_texto(prompt, max_length=100, num_return_sequences=1):\n",
    "    # Tokenizar el texto de entrada\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generar texto\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decodificar y mostrar los resultados\n",
    "    for i, output in enumerate(outputs):\n",
    "        texto_generado = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        print(f\"\\nTexto generado {i+1}:\")\n",
    "        print(texto_generado)\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K7C8DNit1NB"
   },
   "source": [
    "##4) Probar diferentes tipos de generación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsqq9FEet5bd",
    "outputId": "1fd5dfc4-b06f-4ea6-c017-9ca38c6035ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Completando una historia ===\n",
      "\n",
      "Texto generado 1:\n",
      "Había una vez un científico que descubrió la verdad sobre el origen de la materia y la creación de un cuerpo humano. Sin embargo, debido a los acontecimientos que tuvo que suceder durante la guerra, el Imperio de los Estados Unidos perdió su independencia.\n",
      "\n",
      "Al final del juego, la serie vuelve a la normalidad. La historia continúa hasta la primera temporada. El jugador toma el papel de James Ray, un agente de inteligencia que trabaja para la CIA, y es el único miembro del equipo que ha tenido éxito en descubrir la verdadera identidad de las personas que han sido asesinadas por el gobierno de Estados de Unidos. Ray es un hombre de negocios de clase alta y posee un sentido de pertenencia. Se dice que Ray tiene un corazón de oro, lo que le permite\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Generando una receta ===\n",
      "\n",
      "Texto generado 1:\n",
      "Para preparar una tortilla española necesitas una cierta cantidad de grasa y una cantidad significativa de agua, pues la torta puede ser utilizada para comer.\n",
      "\n",
      "La tortas pueden ser preparadas en muchos tamaños y colores: por ejemplo, en la zona del norte de Cataluña se conocen como tortillas de pasta de horno o tortillería, y en el sur de Aragón como «pastelería de torto».\n",
      "El origen de la palabra torecha se remonta al siglo XIX, cuando el francés Jean-Baptiste Leroy, inventor del tort, le introdujo en Francia la idea de que las tortitas se tratasen de diferentes materiales y formas, como harina, huevos, manteca, aceite y otros ingredientes. Su idea se extendió a otros países en los que, a pesar de su nombre, los tortos no fueron utilizados para preparar tormentos, sino para hacer torrezales. Esta denominación se utiliza hoy en día para referirse a los diferentes tipos de huevos que se emplean en torteles\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Generando múltiples variaciones ===\n",
      "\n",
      "Texto generado 1:\n",
      "El futuro de la inteligencia artificial se encuentra en el mundo real.\n",
      "\n",
      "El primer capítulo de \"The Lost and the City of London\" es una adaptación de una novela de John Ruskin \"La piedra filosofal\" que había escrito en 1917. El título se refiere a la novela que se convirtió en un libro de memorias, \"El viaje a través del tiempo\".\n",
      "En la película \"Spy Kids\", en la que el protagonista, el jugador, es llevado a un viaje, y es\n",
      "--------------------------------------------------\n",
      "\n",
      "Texto generado 2:\n",
      "El futuro de la inteligencia artificial se encuentra en el uso de los métodos de inteligencia para crear un nuevo medio para la investigación.\n",
      "\n",
      "El término inteligencia artificiales se utiliza generalmente para describir el proceso de desarrollo de nuevas tecnologías y sistemas que usan la información proveniente de las redes informáticas. Es decir, la ciencia y tecnología de un sistema o la tecnología que usa la mente humana. En la actualidad, el término se refiere a la \"psicardion\" del procesamiento de información. Los sistemas de análisis\n",
      "--------------------------------------------------\n",
      "\n",
      "Texto generado 3:\n",
      "El futuro de la inteligencia artificial y los avances en la tecnología militar de los Estados Unidos han sido de gran interés para la política de Estados de América, especialmente para los países que no están interesados en sus propias actividades. Los esfuerzos por desarrollar nuevas tecnologías militares han tenido éxito en las últimas décadas.\n",
      "\n",
      "Los Estados son los principales promotores de las tecnologías en los campos de ingeniería y la ingeniería civil, y de este modo la industria de Rusia está en auge. Rusia es el mayor productor de motores de turbina\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Completar una historia\n",
    "print(\"=== Completando una historia ===\")\n",
    "prompt_historia = \"Había una vez un científico que descubrió\"\n",
    "generar_texto(prompt_historia, max_length=150)\n",
    "\n",
    "# Ejemplo 2: Generar una receta\n",
    "print(\"\\n=== Generando una receta ===\")\n",
    "prompt_receta = \"Para preparar una tortilla española necesitas\"\n",
    "generar_texto(prompt_receta, max_length=200)\n",
    "\n",
    "# Ejemplo 3: Múltiples variaciones\n",
    "print(\"\\n=== Generando múltiples variaciones ===\")\n",
    "prompt_variaciones = \"El futuro de la inteligencia artificial\"\n",
    "generar_texto(prompt_variaciones, max_length=100, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVR7S2Nft7_M"
   },
   "source": [
    "##5) Funcion Interactiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLTRqaJyuBWC",
    "outputId": "608735ed-8ff6-4fa8-cd67-288e209737c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prueba la generación de texto ===\n",
      "\n",
      "Escribe un comienzo para generar texto: Hola buenos días, \n",
      "¿Cuántos caracteres quieres generar? (recomendado: 100-200): 100\n",
      "¿Cuántas variaciones quieres ver? (1-3): 1\n",
      "\n",
      "Generando texto...\n",
      "\n",
      "Texto generado 1:\n",
      "Hola buenos días, \n",
      "\"Lola bella días\"\n",
      "\n",
      "La canción \"Lolli\" (del álbum \"Los últimos días de mi vida\") es una canción de la banda estadounidense de \"hard rock\" estadounidense Led Zeppelin, publicada por primera vez en 1963. Esta canción se convirtió en un éxito de ventas en los Estados Unidos y en el Reino Unido.\n",
      "Este sencillo es un clásico de Led en la década de 1960, al igual que otros grandes éxitos de The Beatles. Fue\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generar_texto_interactivo():\n",
    "    prompt = input(\"\\nEscribe un comienzo para generar texto: \")\n",
    "    longitud = int(input(\"¿Cuántos caracteres quieres generar? (recomendado: 100-200): \"))\n",
    "    variaciones = int(input(\"¿Cuántas variaciones quieres ver? (1-3): \"))\n",
    "\n",
    "    print(\"\\nGenerando texto...\")\n",
    "    generar_texto(prompt, max_length=longitud, num_return_sequences=variaciones)\n",
    "\n",
    "# Probar la función interactiva\n",
    "print(\"\\n=== Prueba la generación de texto ===\")\n",
    "generar_texto_interactivo()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0uFngshDYbV9oqFI4GE3p",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
