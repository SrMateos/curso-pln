{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE5zN9t2B4H/GOwqavSLz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/03_embeddings_sherlock_holmes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings de Palabras a partir de libros de Sherlock Holmes\n",
        "\n",
        "\n",
        "# 1) Carga de Datos\n",
        "\n",
        "Carga libros publicados en Project Gutenberg y elimina el header/footer:"
      ],
      "metadata": {
        "id": "pgX4RcCCEzfb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr89zm_uEldQ",
        "outputId": "362be36f-f45c-4248-b610-b15f003a189c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando texto desde: https://www.gutenberg.org/files/1661/1661-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/108/108-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/2097/2097-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/244/244-0.txt ..\n",
            "Texto cargado: 1742150 caracteres\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def load_gutenberg_text(url):\n",
        "    print(\"Cargando texto desde:\", url, \"..\")\n",
        "    response = urllib.request.urlopen(url)\n",
        "    raw = response.read().decode('utf-8')\n",
        "\n",
        "    # Encontrar el inicio y fin del contenido real (eliminar header/footer de Gutenberg)\n",
        "    start = raw.find(\"*** START OF THE PROJECT GUTENBERG\")\n",
        "    start = raw.find(\"\\n\", start) + 1\n",
        "    end = raw.find(\"*** END OF THE PROJECT GUTENBERG\")\n",
        "\n",
        "    return raw[start:end]\n",
        "\n",
        "# URLs de los libros en Project Gutenberg\n",
        "urls = [\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\",    # The Adventures of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/108/108-0.txt\",      # The Return of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/2097/2097-0.txt\",    # The Hound of the Baskervilles\n",
        "    \"https://www.gutenberg.org/files/244/244-0.txt\"       # A Study in Scarlet\n",
        "]\n",
        "\n",
        "# Carga y guarda el texto\n",
        "text = \" \"\n",
        "for url in urls:\n",
        "  book_text = load_gutenberg_text(url)\n",
        "  text += book_text\n",
        "\n",
        "\n",
        "print(\"Texto cargado:\", len(text), \"caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preprocesamiento\n",
        "\n",
        "Tokeniza y limpia el texto:\n",
        "* Convierte a minúsculas\n",
        "* Elimina tokens que no son palabras"
      ],
      "metadata": {
        "id": "aEFtcjHpFBD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Inicializar spaCy (solo tokenizador para velocidad)\n",
        "nlp = English(disable=['tagger','parser','ner'])\n",
        "\n",
        "def tokenize(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text.lower() for token in doc\n",
        "            if token.text.strip() and not token.is_punct]\n",
        "\n",
        "# Dividir en oraciones y tokenizar\n",
        "corpus_sentences = []\n",
        "for line in text.split('\\n'):\n",
        "    if line.strip():  # ignorar líneas vacías\n",
        "        tokens = tokenize(line)\n",
        "        if tokens:  # ignorar líneas sin tokens válidos\n",
        "            corpus_sentences.append(tokens)\n",
        "\n",
        "print(\"Total de oraciones procesadas:\", len(corpus_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOY6GToqFB8G",
        "outputId": "04202cc8-90fd-488a-e5f5-69dd57a9e964"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de oraciones procesadas: 27683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Modelo Word2Vec\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAXkjJtYFF0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.26.4 scipy==1.13.1 gensim==4.3.3 spacy==3.7.5\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "WLssPaVaFIOH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1) Entrenamiento"
      ],
      "metadata": {
        "id": "qz6fz_DXFX0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(sentences=corpus_sentences,\n",
        "                    vector_size=300,      # Dimensión del vector (300)\n",
        "                    window=8,             # Ventana más amplia para capturar más contexto (8)\n",
        "                    min_count=2,          # Filtrar palabras poco frecuentes (5)\n",
        "                    workers=4,\n",
        "                    sg=1,                 # Usar Skip-gram\n",
        "                    epochs= 30,           # Más ciclos de entrenamiento\n",
        "                    negative= 15,         # Tamaño de Muestra Negativa (Negative sampling)\n",
        "                    alpha= 0.025,         # Learning rate inicial\n",
        "                    min_alpha= 0.0001     # Learning rate final\n",
        "                  )"
      ],
      "metadata": {
        "id": "-E69AoT3FLt9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar modelos"
      ],
      "metadata": {
        "id": "lUuvM3a_FdVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"sherlock_w2v.model\")"
      ],
      "metadata": {
        "id": "CcwtMCPHFSmx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "Alaz2yIXFV2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar vectores"
      ],
      "metadata": {
        "id": "-Af8SyvvFg24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors = w2v_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", w2v_vectors.vector_size)\n",
        "print(\"Número de palabras (Word2Vec):\", len(w2v_vectors.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yLfuYjtFWWr",
        "outputId": "4654d4b5-ee60-468f-9d07-1c91c1d9bee2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas del modelo:\n",
            "Dimensión de los vectores: 300\n",
            "Número de palabras (Word2Vec): 8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyZz7D9DFk5l",
        "outputId": "3a7cd000-953d-4bc3-fcf7-586ec612cb79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'holmes' (Word2Vec):\n",
            "[('sherlock', 0.5520164370536804), ('demurely', 0.4811103045940399), ('cheerily', 0.4448547959327698), ('gleefully', 0.44213828444480896), ('shrug', 0.4374382197856903), ('approvingly', 0.43318963050842285), ('bungler', 0.4272502064704895), ('inclusive', 0.42610833048820496), ('curtly', 0.425311416387558), ('triumphantly', 0.4236288368701935)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('crime'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLq7S5YvFqXC",
        "outputId": "c0cb7398-6777-4232-dc79-ea42eec16347"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'crime' (Word2Vec):\n",
            "[('committed', 0.5089191794395447), ('records', 0.4670312702655792), ('literature', 0.4545971751213074), ('deliberate', 0.45210957527160645), ('featureless', 0.44890543818473816), ('perpetrator', 0.4422905445098877), ('talent', 0.4386681616306305), ('detect', 0.43413999676704407), ('sots', 0.42703020572662354), ('insane', 0.42568156123161316)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"Word2Vec:\", w2v_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vPFl2EFsUo",
        "outputId": "743e9f7a-bad2-420e-cd80-d731beac18fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similitud entre 'crime' y 'art':\n",
            "Word2Vec: 0.2106922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3) Palabras fuera de vocabulario"
      ],
      "metadata": {
        "id": "SEwj5kfhFu3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "try:\n",
        "    print(\"Word2Vec - Similares a 'investigador':\")\n",
        "    print(w2v_vectors.most_similar('investigador'))\n",
        "except KeyError:\n",
        "    print(\"Word2Vec no puede manejar palabras fuera de vocabulario\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMxXTQUQFwvo",
        "outputId": "d0ccf21d-6954-4e44-9649-69b242240963"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prueba con palabra fuera de vocabulario:\n",
            "Word2Vec - Similares a 'investigador':\n",
            "Word2Vec no puede manejar palabras fuera de vocabulario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4) Analogías"
      ],
      "metadata": {
        "id": "G-wbbEIyF5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAnalogías (Word2Vec):\")\n",
        "result = w2v_vectors.most_similar(positive=['watson', 'crime'],\n",
        "                                negative=['holmes'])\n",
        "print(\"watson:holmes como crime:?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmtgbjYoF3La",
        "outputId": "4486ea72-9f08-45b4-8474-dcd639850f42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analogías (Word2Vec):\n",
            "watson:holmes como crime:?\n",
            "[('contemplation', 0.305237352848053), ('capable', 0.3048299551010132), ('waylaid', 0.29584941267967224), ('comparison', 0.29572513699531555), ('trials', 0.2947629392147064), ('player', 0.292878657579422), ('featureless', 0.29119187593460083), ('sots', 0.2911495268344879), ('unique', 0.29109957814216614), ('reliable', 0.2862240672111511)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) Modelo FastText\n"
      ],
      "metadata": {
        "id": "bBvI1CQgQGLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText"
      ],
      "metadata": {
        "id": "hDk90MunQU2U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1) Entrenamiento"
      ],
      "metadata": {
        "id": "xGyf8y68QhID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = FastText(sentences=corpus_sentences,\n",
        "                   vector_size=300,    # Aumentar dimensionalidad (300)\n",
        "                   window=8,           # Ventana más amplia para capturar más contexto (8)\n",
        "                   min_count=2,        # Mantener min_count bajo para capturar más variantes\n",
        "                   workers=4,\n",
        "                   sg=1,               # Skip-gram para mejor calidad\n",
        "                   min_n=2,            # Tamaño mínimo de n-gramas\n",
        "                   max_n=6,            # Tamaño máximo de n-gramas (aumentado para capturar más patrones)\n",
        "                   epochs=30,          # Más ciclos de entrenamiento (30)\n",
        "                   word_ngrams=1,      # Habilitar n-gramas de palabras\n",
        "                   negative=15,        # Más muestras negativas\n",
        "                   alpha=0.025,        # Learning rate inicial\n",
        "                   min_alpha=0.0001    # Learning rate final\n",
        "              )"
      ],
      "metadata": {
        "id": "qHLPLzC6FNtk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almacenamiento del modelo:"
      ],
      "metadata": {
        "id": "WrD-xvupRPYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save(\"sherlock_ft.model\")"
      ],
      "metadata": {
        "id": "3xwAe7HORRGD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "PjIe1rgrRfB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_vectors = ft_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", ft_vectors.vector_size)\n",
        "print(\"Número de palabras (FastText):\", len(ft_vectors.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWm-jwakRhXM",
        "outputId": "51769a8c-8e30-47a0-8bb2-6b4ecae86d77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas del modelo:\n",
            "Dimensión de los vectores: 300\n",
            "Número de palabras (FastText): 8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (FastText):\")\n",
        "print(ft_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqOEszGBSJfF",
        "outputId": "1134ad01-3239-45aa-9405-ef480c3a34b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'holmes' (FastText):\n",
            "[('holes', 0.4611356258392334), ('sherlock', 0.4445723295211792), ('soames', 0.43678635358810425), ('holborn', 0.4315681457519531), ('volumes', 0.4102344810962677), ('hold', 0.4083307981491089), ('holy', 0.4080694019794464), ('apologies', 0.3960151672363281), ('holds', 0.394469290971756), ('fumes', 0.3857247531414032)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(ft_vectors.most_similar('crime'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi21tk9tSP4m",
        "outputId": "c7cd1156-d3c6-4a48-eaeb-96ea74018139"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'crime' (Word2Vec):\n",
            "[('crimes', 0.804222822189331), ('criticism', 0.653266191482544), ('grime', 0.6352939009666443), ('crib', 0.6334989070892334), ('criminal', 0.6279764771461487), ('criminals', 0.6214247345924377), ('prime', 0.6146371960639954), ('crimson', 0.6062003374099731), ('cripple', 0.5827522873878479), ('crisis', 0.5692859888076782)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"FastText:\", ft_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83OuWC6SVS_",
        "outputId": "de755d1e-7b1d-41da-c7cd-7e5315e23b5b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similitud entre 'crime' y 'art':\n",
            "FastText: 0.0763179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.3) Palabras fuera del vocabulario"
      ],
      "metadata": {
        "id": "kH2SCcT3SiAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "\n",
        "print(\"\\nFastText - Similares a 'investigador':\")\n",
        "print(ft_vectors.most_similar('investigador'))  # FastText puede generar vectores para palabras nuevas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNaWVvPMSkfd",
        "outputId": "3513309a-6d56-47a8-d8e9-d1098d31cf47"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prueba con palabra fuera de vocabulario:\n",
            "\n",
            "FastText - Similares a 'investigador':\n",
            "[('investigate', 0.9274206757545471), ('investigated', 0.9121105074882507), ('investigating', 0.8989437818527222), ('investigations', 0.8705874085426331), ('invest', 0.8689622282981873), ('investigation', 0.8682444095611572), ('investments', 0.7567822933197021), ('domestic', 0.5960216522216797), ('testimonial', 0.5802162885665894), ('destiny', 0.5447513461112976)]\n"
          ]
        }
      ]
    }
  ]
}