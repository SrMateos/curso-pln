{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/06_Ajuste_Fino_Clasificacion_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmYkAE2CObIa"
   },
   "source": [
    "# Ajuste Fino (Fine-Tuning) para Clasificación de Texto\n",
    "\n",
    " Este notebook muestra cómo adaptar un modelo de lenguaje pre-entrenado para realizar clasificación de sentimientos en reseñas de películas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR41MdZkOd_F"
   },
   "source": [
    "## 1) Instalación de Bibliotecas Necesarias\n",
    "\n",
    " Estas son las bibliotecas mínimas que necesitamos:\n",
    " - transformers: para trabajar con modelos de lenguaje\n",
    " - datasets: para cargar y manipular datos\n",
    " - torch: para el procesamiento con deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osWLf9HoOYJh",
    "outputId": "7b31b5c6-f0db-4722-bb0c-f45a473df3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dKWl9LSOoGw"
   },
   "source": [
    "## 2) Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ep7D9vBjOr9d"
   },
   "outputs": [],
   "source": [
    "import torch  # Biblioteca principal para deep learning\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,  # Para cargar el modelo pre-entrenado\n",
    "    AutoTokenizer,  # Para procesar el texto\n",
    "    Trainer,  # Para entrenar el modelo\n",
    "    TrainingArguments,  # Para configurar el entrenamiento\n",
    ")\n",
    "from datasets import load_dataset  # Para cargar los datos\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FadCU8GbOvB5"
   },
   "source": [
    "## 3) Cargar Datos de Ejemplo\n",
    "\n",
    " Usamos un pequeño conjunto de reseñas de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlS3RAAtOr96",
    "outputId": "0fb816f3-cbc5-495b-9f1a-db248697ab9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos de ejemplo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 160\n",
      "Tamaño del conjunto de prueba: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos de ejemplo...\")\n",
    "dataset = load_dataset(\"imdb\", split=\"train[:200]\")  # Solo 200 ejemplos para simplificar\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_test['train'])}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(train_test['test'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6U0A7RKQRI3"
   },
   "source": [
    "## 4) Preparar el Modelo Base\n",
    "\n",
    " Usamos un modelo BERT básico en inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5j3eFpLQUxi",
    "outputId": "0d300c39-4001-4b1f-a95e-88fd07917ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando modelo base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCargando modelo base...\")\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2  # 2 clases: positivo y negativo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr4W1-GnQYGp"
   },
   "source": [
    "## 5) Preparar los Datos\n",
    "\n",
    " Función para convertir texto a formato que entiende el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "8a9ba0169e5d4a49b574da74307b8748",
      "a9c064d9a7f242148d1b669575605986",
      "fe19b630b3974273b40f61a94f918a02",
      "623e539c1ad741788afc48b71fe7b142",
      "465bc4b2225e495bb52027989be320b0",
      "d2b2342201df4b29b81e7941c0edaf48",
      "7954176c6e1545719e334e3fcc560c99",
      "7daeb5cac7144cab942a335fd95065f3",
      "e1a040d0a08f4f669f5b1b7fc26c63d8",
      "a1917c16b5fa498ebe122931e33cccf4",
      "043494ef250e4ea3a24f9bf735bdb8ad"
     ]
    },
    "id": "ViAe7vIIQc0M",
    "outputId": "775365aa-51de-431b-8e02-01c5f81af5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando datos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ba0169e5d4a49b574da74307b8748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preparar_texto(ejemplos):\n",
    "    return tokenizer(\n",
    "        ejemplos[\"text\"],\n",
    "        truncation=True,  # Corta textos muy largos\n",
    "        padding=True,     # Rellena textos cortos\n",
    "        max_length=128    # Longitud máxima de cada texto\n",
    "    )\n",
    "\n",
    "print(\"\\nPreparando datos...\")\n",
    "datos_procesados = train_test.map(preparar_texto, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3OLTiOlQhMK"
   },
   "source": [
    "## 6) Configurar el Entrenamiento\n",
    "\n",
    " Configuración básica para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vTYhFoFzQkVT"
   },
   "outputs": [],
   "source": [
    "argumentos_entrenamiento = TrainingArguments(\n",
    "    output_dir=\"./resultados\",      # Donde guardar resultados\n",
    "    num_train_epochs=3,             # Número de pasadas por los datos\n",
    "    per_device_train_batch_size=8,  # Ejemplos procesados a la vez\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=10,               # Cada cuánto mostrar progreso\n",
    "    report_to=\"none\",              # Desactivar wandb y otros servicios de logging\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhypIDguQoLP"
   },
   "source": [
    "## 7) Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "ygKHXvpQQq1I",
    "outputId": "c92c9d48-0040-49cf-dee5-35542f444011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando el modelo...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nEntrenando el modelo...\")\n",
    "entrenador = Trainer(\n",
    "    model=model,\n",
    "    args=argumentos_entrenamiento,\n",
    "    train_dataset=datos_procesados[\"train\"],\n",
    "    eval_dataset=datos_procesados[\"test\"],\n",
    ")\n",
    "\n",
    "resultado_entrenamiento = entrenador.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US84PmARQujg"
   },
   "source": [
    "## 8) Usar el Modelo\n",
    "\n",
    " Función simple para clasificar nuevo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGvgdJsJRLEA",
    "outputId": "53ad5845-31f3-4baf-9095-12ef54ed6418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probando el modelo:\n",
      "Dispositivo usado: GPU\n",
      "\n",
      "Texto: This movie was fantastic! I really enjoyed it.\n",
      "Sentimiento: Negativo\n",
      "\n",
      "Texto: What a terrible waste of time. I hated it.\n",
      "Sentimiento: Negativo\n"
     ]
    }
   ],
   "source": [
    "# Función simple para clasificar nuevo texto\n",
    "def clasificar_sentimiento(texto):\n",
    "    # Detectar si hay GPU disponible\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)  # Mover el modelo al dispositivo correcto\n",
    "\n",
    "    # Preparar el texto\n",
    "    entradas = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    # Mover las entradas al mismo dispositivo que el modelo\n",
    "    entradas = {k: v.to(device) for k, v in entradas.items()}\n",
    "\n",
    "    # Obtener predicción\n",
    "    with torch.no_grad():\n",
    "        salida = model(**entradas)\n",
    "        prediccion = torch.nn.functional.softmax(salida.logits, dim=-1)\n",
    "\n",
    "    # Mover el resultado a CPU para procesarlo\n",
    "    prediccion = prediccion.cpu()\n",
    "\n",
    "    # Interpretar resultado\n",
    "    if prediccion[0][1] > 0.5:\n",
    "        return \"Positivo\"\n",
    "    else:\n",
    "        return \"Negativo\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"\\nProbando el modelo:\")\n",
    "print(f\"Dispositivo usado: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "ejemplos = [\n",
    "    \"This movie was fantastic! I really enjoyed it.\",\n",
    "    \"What a terrible waste of time. I hated it.\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    for texto in ejemplos:\n",
    "        sentimiento = clasificar_sentimiento(texto)\n",
    "        print(f\"\\nTexto: {texto}\")\n",
    "        print(f\"Sentimiento: {sentimiento}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcurrió un error: {str(e)}\")\n",
    "    print(\"Por favor, asegúrate de que el modelo se haya entrenado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJRHwtQgUnUi"
   },
   "source": [
    "# Mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30Q2qkDGU0N_"
   },
   "source": [
    "## 1) Carga Balanceada de Datos de Entrenamiento\n",
    "\n",
    "Para obtener buenos resultados en tareas de clasificación, es muy importante tener un conjunto de datos balanceado (similar número de ejemplos para cada clase).\n",
    " Si no lo hacemos, el modelo podría aprender sesgos indeseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0b2_549VEPY",
    "outputId": "149dfa3f-5726-42e0-dc94-1ac0c3f2d74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos de ejemplo...\n",
      "\n",
      "Tamaño del conjunto de entrenamiento: 160\n",
      "Tamaño del conjunto de prueba: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos de ejemplo...\")\n",
    "\n",
    "# Cargamos ejemplos negativos y positivos por separado para asegurar el balance\n",
    "negative_examples = load_dataset(\"imdb\", split=\"train[:100]\")  # 100 negativos\n",
    "positive_examples = load_dataset(\"imdb\", split=\"train[12500:12600]\")  # 100 positivos\n",
    "\n",
    "# Combinamos los ejemplos en un solo dataset\n",
    "from datasets import concatenate_datasets\n",
    "dataset = concatenate_datasets([negative_examples, positive_examples])\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "train_test = dataset.train_test_split(test_size=0.2, seed=42)  # seed para reproducibilidad\n",
    "print(f\"\\nTamaño del conjunto de entrenamiento: {len(train_test['train'])}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(train_test['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNwkD4eVVQXB"
   },
   "source": [
    "Verificamos la distribución de clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVO5aVy2VRHv",
    "outputId": "0144cb90-cca7-4ac9-8fb8-d7a69a843aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases en el dataset:\n",
      "Clase 0 (Negativo): 100 ejemplos (50.0%)\n",
      "Clase 1 (Positivo): 100 ejemplos (50.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDistribución de clases en el dataset:\")\n",
    "import numpy as np\n",
    "labels = dataset['label']\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos ({count/len(labels)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lglI5MiDVswF"
   },
   "source": [
    "Ahora puedes continuar en el paso 5 - Preparar los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXYcMYUyXOeT"
   },
   "source": [
    "## 2) Añadir métricas de evaluación durante el entrenamiento\n",
    "\n",
    "Definimos las métricas de accuracy, f-measure (f1), precision y recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "plJV4yUMXZ4V"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VptYwLlMYQ85"
   },
   "source": [
    "Configuramos el entrenamiento para que evalúe esas métricas cada 20 pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tcQz5CX3YXlC"
   },
   "outputs": [],
   "source": [
    "argumentos_entrenamiento = TrainingArguments(\n",
    "    output_dir=\"./resultados\",          # Donde guardar resultados\n",
    "    num_train_epochs=3,                 # Número de pasadas por los datos\n",
    "    per_device_train_batch_size=8,      # Ejemplos procesados a la vez\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=10,                   # Cada cuánto mostrar progreso\n",
    "    eval_steps=20,                      # Cada cuántos pasos evaluar\n",
    "    eval_strategy=\"steps\",              # Evaluar durante el entrenamiento\n",
    "    load_best_model_at_end=True,       # Cargar el mejor modelo al final\n",
    "    metric_for_best_model=\"f1\",        # Métrica para elegir el mejor modelo\n",
    "    report_to=\"none\",                  # Desactivar wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pSqmk-oXkGB"
   },
   "source": [
    "Entrenamos y evaluamos al mismo tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LQI3RqT1Xp3_",
    "outputId": "3226144c-2e98-46dd-dbd3-d76e144a9de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando el modelo...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.720396</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.835547</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.887140</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nEntrenando el modelo...\")\n",
    "entrenador = Trainer(\n",
    "    model=model,\n",
    "    args=argumentos_entrenamiento,\n",
    "    train_dataset=datos_procesados[\"train\"],\n",
    "    eval_dataset=datos_procesados[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "resultado_entrenamiento = entrenador.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnjzB8Ux7YMZ2Uh/9fMISp",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
